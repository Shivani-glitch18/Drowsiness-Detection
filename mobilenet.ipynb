{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f858c686-8836-4cd2-b661-be1505360526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54336 images belonging to 2 classes.\n",
      "Found 13583 images belonging to 2 classes.\n",
      "Found 16979 images belonging to 2 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajat\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9023 - loss: 0.2359\n",
      "Epoch 1: val_loss improved from inf to 0.40939, saving model to C:\\Users\\rajat\\OneDrive\\Desktop\\drowsiness\\Project\\mobilenet_model_checkpoint.keras\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3829s\u001b[0m 4s/step - accuracy: 0.9023 - loss: 0.2358 - val_accuracy: 0.8707 - val_loss: 0.4094 - learning_rate: 0.0010\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajat\\anaconda3\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss did not improve from 0.40939\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9333 - val_loss: 0.5688 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9441 - loss: 0.1434\n",
      "Epoch 3: val_loss did not improve from 0.40939\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3224s\u001b[0m 4s/step - accuracy: 0.9441 - loss: 0.1434 - val_accuracy: 0.8572 - val_loss: 0.4594 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.40939\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8667 - val_loss: 0.6713 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9586 - loss: 0.1099\n",
      "Epoch 5: val_loss improved from 0.40939 to 0.38599, saving model to C:\\Users\\rajat\\OneDrive\\Desktop\\drowsiness\\Project\\mobilenet_model_checkpoint.keras\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2881s\u001b[0m 3s/step - accuracy: 0.9586 - loss: 0.1099 - val_accuracy: 0.8824 - val_loss: 0.3860 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.38599\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8667 - val_loss: 0.5079 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9612 - loss: 0.1024\n",
      "Epoch 7: val_loss did not improve from 0.38599\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2743s\u001b[0m 3s/step - accuracy: 0.9612 - loss: 0.1024 - val_accuracy: 0.8753 - val_loss: 0.4063 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 8: val_loss improved from 0.38599 to 0.26648, saving model to C:\\Users\\rajat\\OneDrive\\Desktop\\drowsiness\\Project\\mobilenet_model_checkpoint.keras\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8000 - val_loss: 0.2665 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9614 - loss: 0.1047\n",
      "Epoch 9: val_loss did not improve from 0.26648\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2960s\u001b[0m 3s/step - accuracy: 0.9614 - loss: 0.1047 - val_accuracy: 0.8815 - val_loss: 0.3740 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.26648\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8000 - val_loss: 0.6829 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9615 - loss: 0.1023\n",
      "Epoch 11: val_loss did not improve from 0.26648\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3184s\u001b[0m 4s/step - accuracy: 0.9615 - loss: 0.1023 - val_accuracy: 0.8716 - val_loss: 0.4431 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 12: val_loss improved from 0.26648 to 0.10796, saving model to C:\\Users\\rajat\\OneDrive\\Desktop\\drowsiness\\Project\\mobilenet_model_checkpoint.keras\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9333 - val_loss: 0.1080 - learning_rate: 1.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9625 - loss: 0.0988\n",
      "Epoch 13: val_loss did not improve from 0.10796\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2962s\u001b[0m 3s/step - accuracy: 0.9625 - loss: 0.0988 - val_accuracy: 0.8718 - val_loss: 0.4305 - learning_rate: 1.0000e-05\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.10796\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9333 - val_loss: 0.1233 - learning_rate: 1.0000e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9645 - loss: 0.0964\n",
      "Epoch 15: val_loss did not improve from 0.10796\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2717s\u001b[0m 3s/step - accuracy: 0.9645 - loss: 0.0964 - val_accuracy: 0.8769 - val_loss: 0.4097 - learning_rate: 1.0000e-05\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.10796\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8667 - val_loss: 0.3351 - learning_rate: 1.0000e-06\n",
      "Epoch 17/30\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9631 - loss: 0.0970\n",
      "Epoch 17: val_loss did not improve from 0.10796\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2915s\u001b[0m 3s/step - accuracy: 0.9631 - loss: 0.0970 - val_accuracy: 0.8723 - val_loss: 0.4213 - learning_rate: 1.0000e-06\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.10796\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9333 - val_loss: 0.4601 - learning_rate: 1.0000e-06\n",
      "Epoch 19/30\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9621 - loss: 0.0987\n",
      "Epoch 19: val_loss did not improve from 0.10796\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2804s\u001b[0m 3s/step - accuracy: 0.9621 - loss: 0.0987 - val_accuracy: 0.8732 - val_loss: 0.4265 - learning_rate: 1.0000e-07\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 1s/step - accuracy: 0.9336 - loss: 0.1823\n",
      "Test Accuracy: 0.9396902322769165\n",
      "Test Loss: 0.17413046956062317\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      closed       0.49      0.48      0.49      8389\n",
      "        open       0.50      0.51      0.51      8590\n",
      "\n",
      "    accuracy                           0.50     16979\n",
      "   macro avg       0.50      0.50      0.50     16979\n",
      "weighted avg       0.50      0.50      0.50     16979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Data Augmentation Parameters\n",
    "batchsize = 64  # Increase batch size for faster training\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, shear_range=0.2,\n",
    "                                   zoom_range=0.2, width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2, validation_split=0.2)\n",
    "\n",
    "# Data Generators\n",
    "train_data = train_datagen.flow_from_directory(r'C:\\Users\\rajat\\OneDrive\\Desktop\\drowsiness\\data\\train',\n",
    "                                               target_size=(224, 224), batch_size=batchsize,\n",
    "                                               class_mode='categorical', subset='training')\n",
    "\n",
    "validation_data = train_datagen.flow_from_directory(r'C:\\Users\\rajat\\OneDrive\\Desktop\\drowsiness\\data\\train',\n",
    "                                                    target_size=(224, 224), batch_size=batchsize,\n",
    "                                                    class_mode='categorical', subset='validation')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(r'C:\\Users\\rajat\\OneDrive\\Desktop\\drowsiness\\data\\test',\n",
    "                                             target_size=(224, 224), batch_size=batchsize,\n",
    "                                             class_mode='categorical')\n",
    "\n",
    "# Base model\n",
    "base_model = MobileNetV2(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n",
    "\n",
    "# Add custom head to the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# Combined model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze layers in base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_path = r'C:\\Users\\rajat\\OneDrive\\Desktop\\drowsiness\\Project\\mobilenet_model_checkpoint.keras'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=7, verbose=1, restore_best_weights=True)\n",
    "\n",
    "learning_rate = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1)\n",
    "\n",
    "callbacks = [checkpoint, earlystop, learning_rate]\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data,\n",
    "                    steps_per_epoch=train_data.samples // batchsize,\n",
    "                    validation_data=validation_data,\n",
    "                    validation_steps=validation_data.samples // batchsize,\n",
    "                    callbacks=callbacks,\n",
    "                    epochs=30)\n",
    "\n",
    "# Load the best model\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss_test, acc_test = model.evaluate(test_data)\n",
    "\n",
    "# Print the test accuracy and loss\n",
    "print(\"Test Accuracy:\", acc_test)\n",
    "print(\"Test Loss:\", loss_test)\n",
    "\n",
    "# Get predictions for the test data\n",
    "predictions = model.predict(test_data)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Map class indices to class labels\n",
    "class_labels = list(test_data.class_indices.keys())\n",
    "\n",
    "# Get true labels for the test data\n",
    "true_classes = test_data.classes\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "\n",
    "# Print the classification report\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d7e427-9e32-4579-95e3-cd532efb6b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
