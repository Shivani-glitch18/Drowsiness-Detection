{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "862ced5d-670c-4c28-8446-b4ede074ac8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54336 images belonging to 2 classes.\n",
      "Found 13583 images belonging to 2 classes.\n",
      "Found 16979 images belonging to 2 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 0us/step\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajat\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5001 - loss: 0.7857\n",
      "Epoch 1: val_loss improved from inf to 0.69311, saving model to C:\\Users\\rajat\\OneDrive\\Desktop\\drowsiness\\Project\\trainmodels_resnet.keras\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4478s\u001b[0m 5s/step - accuracy: 0.5001 - loss: 0.7856 - val_accuracy: 0.5060 - val_loss: 0.6931 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajat\\anaconda3\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss did not improve from 0.69311\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.4667 - val_loss: 0.6934 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5091 - loss: 0.6931\n",
      "Epoch 3: val_loss improved from 0.69311 to 0.69309, saving model to C:\\Users\\rajat\\OneDrive\\Desktop\\drowsiness\\Project\\trainmodels_resnet.keras\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4300s\u001b[0m 5s/step - accuracy: 0.5091 - loss: 0.6931 - val_accuracy: 0.5059 - val_loss: 0.6931 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 4: val_loss improved from 0.69309 to 0.69265, saving model to C:\\Users\\rajat\\OneDrive\\Desktop\\drowsiness\\Project\\trainmodels_resnet.keras\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5333 - val_loss: 0.6927 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5065 - loss: 0.6931\n",
      "Epoch 5: val_loss did not improve from 0.69265\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4372s\u001b[0m 5s/step - accuracy: 0.5065 - loss: 0.6931 - val_accuracy: 0.5061 - val_loss: 0.6931 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.69265\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.3333 - val_loss: 0.6963 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5045 - loss: 0.6931\n",
      "Epoch 7: val_loss did not improve from 0.69265\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4203s\u001b[0m 5s/step - accuracy: 0.5045 - loss: 0.6931 - val_accuracy: 0.5057 - val_loss: 0.6931 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 8: val_loss improved from 0.69265 to 0.68782, saving model to C:\\Users\\rajat\\OneDrive\\Desktop\\drowsiness\\Project\\trainmodels_resnet.keras\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7333 - val_loss: 0.6878 - learning_rate: 1.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5079 - loss: 0.6930\n",
      "Epoch 9: val_loss did not improve from 0.68782\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4254s\u001b[0m 5s/step - accuracy: 0.5079 - loss: 0.6930 - val_accuracy: 0.5059 - val_loss: 0.6931 - learning_rate: 1.0000e-05\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.68782\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5333 - val_loss: 0.6924 - learning_rate: 1.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5035 - loss: 0.6931\n",
      "Epoch 11: val_loss did not improve from 0.68782\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4336s\u001b[0m 5s/step - accuracy: 0.5036 - loss: 0.6931 - val_accuracy: 0.5059 - val_loss: 0.6931 - learning_rate: 1.0000e-05\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.68782\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.5333 - val_loss: 0.6924 - learning_rate: 1.0000e-06\n",
      "Epoch 13/30\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5039 - loss: 0.6931\n",
      "Epoch 13: val_loss did not improve from 0.68782\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4316s\u001b[0m 5s/step - accuracy: 0.5039 - loss: 0.6931 - val_accuracy: 0.5061 - val_loss: 0.6931 - learning_rate: 1.0000e-06\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.68782\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.3333 - val_loss: 0.6971 - learning_rate: 1.0000e-06\n",
      "Epoch 15/30\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5023 - loss: 0.6932\n",
      "Epoch 15: val_loss did not improve from 0.68782\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3710s\u001b[0m 4s/step - accuracy: 0.5023 - loss: 0.6932 - val_accuracy: 0.5060 - val_loss: 0.6931 - learning_rate: 1.0000e-07\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "\u001b[1m849/849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2048s\u001b[0m 2s/step - accuracy: 0.5075 - loss: 0.6930\n",
      "Training Accuracy: 0.5059260725975037\n",
      "Training Loss: 0.6930774450302124\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m512s\u001b[0m 2s/step - accuracy: 0.4995 - loss: 0.6932\n",
      "Validation Accuracy: 0.5059265494346619\n",
      "Validation Loss: 0.6930768489837646\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 2s/step - accuracy: 0.5025 - loss: 0.6932\n",
      "Test Accuracy: 0.5059190988540649\n",
      "Test Loss: 0.6930772066116333\n",
      "\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m641s\u001b[0m 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      closed       0.00      0.00      0.00      8389\n",
      "        open       0.51      1.00      0.67      8590\n",
      "\n",
      "    accuracy                           0.51     16979\n",
      "   macro avg       0.25      0.50      0.34     16979\n",
      "weighted avg       0.26      0.51      0.34     16979\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajat\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rajat\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\rajat\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Data Augmentation Parameters\n",
    "batchsize = 64  # Increase batch size for faster training\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, shear_range=0.2,\n",
    "                                   zoom_range=0.2, width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2, validation_split=0.2)\n",
    "\n",
    "# Data Generators\n",
    "train_data = train_datagen.flow_from_directory(r'C:\\Users\\rajat\\OneDrive\\Desktop\\drowsiness\\data\\train',\n",
    "                                               target_size=(224, 224), batch_size=batchsize,\n",
    "                                               class_mode='categorical', subset='training')\n",
    "\n",
    "validation_data = train_datagen.flow_from_directory(r'C:\\Users\\rajat\\OneDrive\\Desktop\\drowsiness\\data\\train',\n",
    "                                                    target_size=(224, 224), batch_size=batchsize,\n",
    "                                                    class_mode='categorical', subset='validation')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(r'C:\\Users\\rajat\\OneDrive\\Desktop\\drowsiness\\data\\test',\n",
    "                                             target_size=(224, 224), batch_size=batchsize,\n",
    "                                             class_mode='categorical')\n",
    "\n",
    "# Base model\n",
    "bmodel = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "# Model head\n",
    "hmodel = bmodel.output\n",
    "hmodel = Flatten()(hmodel)\n",
    "hmodel = Dense(128, activation='relu')(hmodel)  # Increase number of neurons\n",
    "hmodel = Dropout(0.5)(hmodel)  # Increase dropout rate to reduce overfitting\n",
    "hmodel = Dense(64, activation='relu')(hmodel)\n",
    "hmodel = Dropout(0.5)(hmodel)\n",
    "hmodel = Dense(2, activation='softmax')(hmodel)\n",
    "\n",
    "# Combined model\n",
    "model = Model(inputs=bmodel.input, outputs=hmodel)\n",
    "\n",
    "# Freeze layers in base model\n",
    "for layer in bmodel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_path = r'C:\\Users\\rajat\\OneDrive\\Desktop\\drowsiness\\Project\\trainmodels_resnet.keras'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=7, verbose=1, restore_best_weights=True)\n",
    "\n",
    "learning_rate = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1)\n",
    "\n",
    "callbacks = [checkpoint, earlystop, learning_rate]\n",
    "\n",
    "# Adjust Learning Rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)  # Reduce learning rate for smoother convergence\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tuning (unfreeze some layers for fine-tuning)\n",
    "for layer in bmodel.layers[-30:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Train the model with increased number of epochs\n",
    "model.fit(train_data,\n",
    "          steps_per_epoch=train_data.samples // batchsize,\n",
    "          validation_data=validation_data,\n",
    "          validation_steps=validation_data.samples // batchsize,\n",
    "          callbacks=callbacks,\n",
    "          epochs=30)\n",
    "\n",
    "# Load the saved model\n",
    "#model = tf.keras.models.load_model(r'C:\\Users\\rajat\\OneDrive\\Desktop\\drowsiness\\Project\\trainmodels.keras')\n",
    "\n",
    "# Evaluate the model on the training data generator\n",
    "loss_tr, acc_tr = model.evaluate(train_data)\n",
    "\n",
    "# Print the training accuracy and loss\n",
    "print(\"Training Accuracy:\", acc_tr)\n",
    "print(\"Training Loss:\", loss_tr)\n",
    "\n",
    "# Evaluate the model on the validation data generator\n",
    "loss_vr, acc_vr = model.evaluate(validation_data)\n",
    "\n",
    "# Print the validation accuracy and loss\n",
    "print(\"Validation Accuracy:\", acc_vr)\n",
    "print(\"Validation Loss:\", loss_vr)\n",
    "\n",
    "# Evaluate the model on the test data generator\n",
    "loss_test, acc_test = model.evaluate(test_data)\n",
    "\n",
    "# Print the test accuracy and loss\n",
    "print(\"Test Accuracy:\", acc_test)\n",
    "print(\"Test Loss:\", loss_test)\n",
    "\n",
    "# Get predictions for the test data\n",
    "predictions = model.predict(test_data)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Map class indices to class labels\n",
    "class_labels = list(test_data.class_indices.keys())\n",
    "\n",
    "# Get true labels for the test data\n",
    "true_classes = test_data.classes\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "\n",
    "# Print the classification report\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26990f68-faf5-4569-b5cd-543072863fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
